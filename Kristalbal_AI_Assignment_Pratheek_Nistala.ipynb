{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/hlCdwYE/k1oD7NK9J/P0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prtk2403/kristalbal_assignment/blob/main/Kristalbal_AI_Assignment_Pratheek_Nistala.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis performed by - Pratheek Nistala (21BDS0181)\n",
        "\n",
        "---\n",
        "Contact Information\n",
        "\n",
        "[Github](https://github.com/prtk2403) <br/>\n",
        "[X](https://x.com/xyzprtk)"
      ],
      "metadata": {
        "id": "Ra1Awissvvs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**\n",
        "\n",
        "This analysis was performed on Sunday, May 25, 2024, at 11:20 AM. While the time and location (Hyderabad, Telangana, India) are noted, they do not have a material impact on the analysis of the historical dataset provided."
      ],
      "metadata": {
        "id": "xSYKwIAcvhtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1\\. The Business Problem**\n",
        "\n",
        "A hotel chain is facing a significant challenge in managing the inventory for its bars across multiple locations. The core problem is a recurring pattern of **stockouts** on high-demand items and **overstocking** of slow-moving items. These issues lead to:\n",
        "\n",
        "*   **Increased Operational Costs**: Overstocking ties up capital in unsold inventory, leading to storage costs and potential spoilage. Stockouts of popular items can lead to lost sales opportunities.\n",
        "    \n",
        "*   **Decreased Guest Satisfaction**: When guests cannot order their preferred drinks, it leads to a negative experience, potentially impacting their overall perception of the hotel and their loyalty.\n",
        "    "
      ],
      "metadata": {
        "id": "qMdYKCwxxFJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to develop a data-driven system to forecast demand for each beverage and recommend optimal inventory levels to be maintained at each bar. This will help the hotel chain to:\n",
        "\n",
        "*   **Minimize Stockouts**: Ensure that popular items are always available, maximizing revenue and guest satisfaction.\n",
        "    \n",
        "*   **Reduce Overstocking**: Free up capital and reduce waste by holding less of the slow-moving inventory.\n",
        "    \n",
        "*   **Automate and Standardize**: Provide a consistent and automated way for bar managers to make inventory decisions, reducing the reliance on guesswork and manual processes."
      ],
      "metadata": {
        "id": "5I_bOFQexGz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**2\\. Data Exploration and Preprocessing**\n",
        "\n",
        "First, we load the dataset and perform some initial exploration to understand its structure and content. The dataset contains records of alcohol consumption from different bars, including the date and time of service, bar name, alcohol type, brand, and consumption data"
      ],
      "metadata": {
        "id": "vHS_8rHExasz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
        "from google.colab import files\n",
        "import io\n",
        "print(\"Please upload your dataset.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check if the file was uploaded and get its name\n",
        "filename = next(iter(uploaded))\n",
        "print(f\"\\nReading the uploaded file: {filename}\")\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "print(\"\\nDataset information:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nMissing values count:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "K2mwbjBCvhOk",
        "outputId": "4dfeb4d5-5416-4c14-e33d-9dded349f24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your dataset.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b31fa0d-b411-4f77-a886-a18843229cda\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b31fa0d-b411-4f77-a886-a18843229cda\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Consumption Dataset - Dataset.csv to Consumption Dataset - Dataset (1).csv\n",
            "\n",
            "Reading the uploaded file: Consumption Dataset - Dataset (1).csv\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "  Date Time Served       Bar Name Alcohol Type      Brand Name  \\\n",
            "0   1/1/2023 19:35    Smith's Bar          Rum  Captain Morgan   \n",
            "1   1/1/2023 10:07    Smith's Bar         Wine     Yellow Tail   \n",
            "2   1/1/2023 11:26  Johnson's Bar        Vodka      Grey Goose   \n",
            "3   1/1/2023 13:53  Johnson's Bar         Beer           Coors   \n",
            "4   1/1/2023 22:28  Johnson's Bar         Wine     Yellow Tail   \n",
            "\n",
            "   Opening Balance (ml)  Purchase (ml)  Consumed (ml)  Closing Balance (ml)  \n",
            "0               2555.04        1824.84            0.0               4379.88  \n",
            "1               1344.37           0.00            0.0               1344.37  \n",
            "2               1034.28           0.00            0.0               1034.28  \n",
            "3               2194.53           0.00            0.0               2194.53  \n",
            "4               1020.90           0.00            0.0               1020.90  \n",
            "\n",
            "Dataset information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6575 entries, 0 to 6574\n",
            "Data columns (total 8 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Date Time Served      6575 non-null   object \n",
            " 1   Bar Name              6575 non-null   object \n",
            " 2   Alcohol Type          6575 non-null   object \n",
            " 3   Brand Name            6575 non-null   object \n",
            " 4   Opening Balance (ml)  6575 non-null   float64\n",
            " 5   Purchase (ml)         6575 non-null   float64\n",
            " 6   Consumed (ml)         6575 non-null   float64\n",
            " 7   Closing Balance (ml)  6575 non-null   float64\n",
            "dtypes: float64(4), object(4)\n",
            "memory usage: 411.1+ KB\n",
            "\n",
            "Missing values count:\n",
            "Date Time Served        0\n",
            "Bar Name                0\n",
            "Alcohol Type            0\n",
            "Brand Name              0\n",
            "Opening Balance (ml)    0\n",
            "Purchase (ml)           0\n",
            "Consumed (ml)           0\n",
            "Closing Balance (ml)    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data needs to be preprocessed to make it suitable for time-series forecasting. We will:\n",
        "\n",
        "1.  Convert the 'Date Time Served' column to a datetime object and set it as the index.\n",
        "    \n",
        "2.  Create a unique identifier for each item at each bar by combining 'Bar Name', 'Alcohol Type', and 'Brand Name'.\n",
        "    \n",
        "3.  Aggregate the consumption data by day for each unique item.\n",
        "    "
      ],
      "metadata": {
        "id": "paX_VLjKykOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date Time Served' to datetime and set as index\n",
        "df['Date Time Served'] = pd.to_datetime(df['Date Time Served'])\n",
        "df.set_index('Date Time Served', inplace=True)\n",
        "\n",
        "# Create a unique item identifier\n",
        "df['Item'] = df['Bar Name'] + ' - ' + df['Alcohol Type'] + ' - ' + df['Brand Name']\n",
        "\n",
        "# Aggregate consumption by day for each item\n",
        "daily_consumption = df.groupby(['Item', pd.Grouper(freq='D')])['Consumed (ml)'].sum().reset_index()\n",
        "daily_consumption.rename(columns={'Date Time Served': 'Date'}, inplace=True)\n",
        "\n",
        "# Display the aggregated data\n",
        "print(daily_consumption.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1yhK8Ziyj9n",
        "outputId": "d8ec6b1e-598d-4d9a-de75-7be9855982ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                Item       Date  Consumed (ml)\n",
            "0  Anderson's Bar - Beer - Budweiser 2023-01-09         159.07\n",
            "1  Anderson's Bar - Beer - Budweiser 2023-01-18         238.21\n",
            "2  Anderson's Bar - Beer - Budweiser 2023-01-21         303.50\n",
            "3  Anderson's Bar - Beer - Budweiser 2023-01-29         238.29\n",
            "4  Anderson's Bar - Beer - Budweiser 2023-02-02         225.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3\\. Assumptions**\n",
        "\n",
        "In any real-world modeling project, we need to make some assumptions. Here are the key assumptions for this project:\n",
        "\n",
        "*   **Lead Time**: We assume a constant lead time of **3 days** for all items. This is the time it takes from placing an order to receiving the delivery. In a real-world scenario, this could be more dynamic.\n",
        "    \n",
        "*   **Service Level**: We are aiming for a **95% service level**, which means we want to be in-stock 95% of the time. This corresponds to a Z-score of approximately 1.65.\n",
        "    \n",
        "*   **Review Period**: We assume that the inventory is reviewed and orders are placed **daily**."
      ],
      "metadata": {
        "id": "q5riUV5dyt7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4\\. Demand Forecasting**\n",
        "\n",
        "We will forecast the demand for each item at each bar. We'll start with a simple baseline model and then use a more sophisticated forecasting model.\n",
        "\n",
        "#### **4.1. Baseline Model: Simple Moving Average (SMA)**\n",
        "\n",
        "A simple moving average is a good baseline to see how a simple model performs. We will use a 7-day moving average to predict the next day's demand."
      ],
      "metadata": {
        "id": "ohrAkMp7yuzP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sLwMNYiWkOv",
        "outputId": "be3b162a-4bf9-49fd-8f1f-5908674ac94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMA Forecast for next day: 277.14 ml\n"
          ]
        }
      ],
      "source": [
        "def sma_forecast(series, window):\n",
        "    \"\"\"Calculates the simple moving average forecast.\"\"\"\n",
        "    return series.rolling(window).mean().iloc[-1]\n",
        "\n",
        "# For Example\n",
        "item_data = daily_consumption[daily_consumption['Item'] == \"Smith's Bar - Rum - Captain Morgan\"].set_index('Date')['Consumed (ml)']\n",
        "sma_pred = sma_forecast(item_data, 7)\n",
        "print(f\"SMA Forecast for next day: {sma_pred:.2f} ml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2. Exponential Smoothing Model**\n",
        "\n",
        "Exponential smoothing is a robust forecasting method that is easy to implement and works well for many time series. It's a good choice for this problem because it can capture trends and seasonality in the data. We will use the Holt-Winters method, which can model both trend and seasonality."
      ],
      "metadata": {
        "id": "xms6OSjCy8W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the data for a single item\n",
        "item_data_raw = daily_consumption[daily_consumption['Item'] == \"Smith's Bar - Rum - Captain Morgan\"].set_index('Date')['Consumed (ml)']\n",
        "item_data = item_data_raw.asfreq('D').fillna(0)\n",
        "\n",
        "def exponential_smoothing_forecast(series, trend='add', seasonal='add', seasonal_periods=7):\n",
        "    \"\"\"Calculates the exponential smoothing forecast.\"\"\"\n",
        "    fit = ExponentialSmoothing(\n",
        "        series,\n",
        "        seasonal_periods=seasonal_periods,\n",
        "        trend=trend,\n",
        "        seasonal=seasonal,\n",
        "        initialization_method=\"estimated\",\n",
        "    ).fit()\n",
        "    return fit.forecast(1).iloc[0]\n",
        "\n",
        "# Example\n",
        "es_pred = exponential_smoothing_forecast(item_data)\n",
        "print(f\"Exponential Smoothing Forecast for next day: {es_pred:.2f} ml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t-YowIHy9MA",
        "outputId": "bdc2d22e-ac50-4651-9d9d-80deee53abfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exponential Smoothing Forecast for next day: 56.91 ml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5\\. Inventory Recommendation System**\n",
        "\n",
        "Now that we have a demand forecast, we can build the inventory recommendation system. The system will calculate the following for each item:\n",
        "\n",
        "*   **Safety Stock**: Extra stock to buffer against forecast inaccuracies and demand variability.\n",
        "    \n",
        "    *   Safety Stock = Z-score \\* Standard Deviation of Lead Time Demand\n",
        "        \n",
        "*   **Reorder Point (ROP)**: The inventory level at which a new order should be placed.\n",
        "    \n",
        "    *   Reorder Point = (Average Daily Usage \\* Lead Time) + Safety Stock\n",
        "        \n",
        "*   **Par Level (Order-up-to-Level)**: The maximum desired inventory level.\n",
        "    \n",
        "    *   Par Level = Reorder Point + Average consumption during the review period\n",
        "        "
      ],
      "metadata": {
        "id": "QmTo8rRhz_TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_inventory_levels(series, lead_time=3, service_level_z=1.65):\n",
        "    \"\"\"Calculates safety stock, reorder point, and par level.\"\"\"\n",
        "    avg_daily_usage = series.mean()\n",
        "    std_daily_usage = series.std()\n",
        "\n",
        "    # Calculate standard deviation of lead time demand\n",
        "    std_lead_time_demand = std_daily_usage * np.sqrt(lead_time)\n",
        "\n",
        "    # Calculate safety stock\n",
        "    safety_stock = service_level_z * std_lead_time_demand\n",
        "\n",
        "    # Calculate reorder point\n",
        "    reorder_point = (avg_daily_usage * lead_time) + safety_stock\n",
        "\n",
        "    # Calculate par level\n",
        "    par_level = reorder_point + avg_daily_usage\n",
        "\n",
        "    return {\n",
        "        'Safety Stock (ml)': safety_stock,\n",
        "        'Reorder Point (ml)': reorder_point,\n",
        "        'Par Level (ml)': par_level\n",
        "    }\n",
        "\n",
        "# For Example\n",
        "inventory_levels = calculate_inventory_levels(item_data)\n",
        "print(inventory_levels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpDQm-Eu0AUC",
        "outputId": "6cc1443e-d339-4347-bb27-34c747b5f44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Safety Stock (ml)': np.float64(403.47269796122043), 'Reorder Point (ml)': np.float64(584.7785176333516), 'Par Level (ml)': np.float64(645.2137908573953)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6\\. Simulation**\n",
        "\n",
        "To understand how our system would perform in practice, we will run a simulation. The simulation will track inventory levels over time, using our forecasting and inventory recommendation logic. We will track key performance indicators (KPIs) like stockouts and service level."
      ],
      "metadata": {
        "id": "b_Pkq_mG0OMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_inventory(series, lead_time=3, service_level_z=1.65):\n",
        "    \"\"\"Simulates inventory management over a period.\"\"\"\n",
        "    inventory_levels = calculate_inventory_levels(series, lead_time, service_level_z)\n",
        "    par_level = inventory_levels['Par Level (ml)']\n",
        "\n",
        "    inventory = par_level\n",
        "    stockout_days = 0\n",
        "\n",
        "    for demand in series:\n",
        "        if inventory < demand:\n",
        "            stockout_days += 1\n",
        "            inventory = 0\n",
        "        else:\n",
        "            inventory -= demand\n",
        "\n",
        "        # Replenish inventory to par level at the end of the day\n",
        "        inventory = par_level\n",
        "\n",
        "    service_level = (len(series) - stockout_days) / len(series) * 100\n",
        "    return {\n",
        "        'Total Days': len(series),\n",
        "        'Stockout Days': stockout_days,\n",
        "        'Service Level (%)': service_level\n",
        "    }\n",
        "\n",
        "# For Example\n",
        "simulation_results = simulate_inventory(item_data)\n",
        "print(simulation_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsTQbjOH0Ox7",
        "outputId": "109bd955-59e9-49d3-967e-5d1642007f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Total Days': 366, 'Stockout Days': 0, 'Service Level (%)': 100.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7\\. Report and Conclusion**\n",
        "\n",
        "#### **7.1. How the System Performs and Potential Improvements**\n",
        "\n",
        "The system's performance, based on the simulation, is quite good. For the example item, we achieved a high service level, which means we were able to meet customer demand most of the time.\n",
        "\n",
        "**Improvements**:\n",
        "\n",
        "*   **Dynamic Lead Times**: Incorporate dynamic lead time forecasting, as supplier lead times can vary.\n",
        "    \n",
        "*   **Promotions and Events**: The model can be improved by including a feature that accounts for promotions, holidays, and local events, which can significantly impact demand.\n",
        "    \n",
        "*   **More Sophisticated Models**: For items with complex demand patterns, more advanced models like SARIMA or machine learning models (e.g., Gradient Boosting, LSTMs) could be explored.\n",
        "    "
      ],
      "metadata": {
        "id": "V51T03oQ0cPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **7.2. Real-World Implementation**\n",
        "\n",
        "To implement this solution in a real hotel, the following steps would be necessary:\n",
        "\n",
        "1.  **Data Integration**: Set up an automated pipeline to collect and process consumption data from the hotel's Point of Sale (POS) system in near real-time.\n",
        "    \n",
        "2.  **Dashboarding**: Create a user-friendly dashboard for bar managers that displays the demand forecasts, recommended inventory levels, and alerts for items that are running low.\n",
        "    \n",
        "3.  **Training**: Train bar managers on how to use the system and interpret the recommendations.\n",
        "    \n",
        "4.  **Monitoring and Retraining**: Continuously monitor the model's performance and retrain it periodically with new data to ensure it remains accurate."
      ],
      "metadata": {
        "id": "RFxYsljD0c_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **7.3. (Optional) Scalability and Production Monitoring**\n",
        "\n",
        "*   **Scalability**: At scale, the system would need to handle data from hundreds of bars and thousands of items. This would require a robust data infrastructure, likely using cloud-based services for data storage (e.g., a data warehouse) and computation (e.g., a distributed computing framework like Spark).\n",
        "    \n",
        "*   **Production Monitoring**: In a production environment, we would need to track:\n",
        "    \n",
        "    *   **Model Accuracy**: Metrics like Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) to track how well the forecasts are performing.\n",
        "        \n",
        "    *   **Business KPIs**: Track the impact on key business metrics like stockout rates, inventory turnover, and guest satisfaction scores to measure the system's ROI."
      ],
      "metadata": {
        "id": "-NPAfLaE0ke_"
      }
    }
  ]
}